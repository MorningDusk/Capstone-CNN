{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7a0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tensorflow import keras\n",
    "import os  \n",
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a8968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRN50():\n",
    "    return [\n",
    "        ## S\n",
    "        {'c': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/connector.h5'),\n",
    "        'ms': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/multiscrew.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/screw2.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/supporter3.h5')},\n",
    "        ## M\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/connector2.h5'),\n",
    "        'ms1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/multiscrew1.h5'),\n",
    "        'ms2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/multiscrew2.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter3.h5')},\n",
    "        ## AS\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/connector2.h5'),\n",
    "        'ms': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/multiscrew.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter3.h5'),\n",
    "        'sp4': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter4.h5')},\n",
    "        ## AM\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector2.h5'),\n",
    "        'c3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector3.h5'),\n",
    "        'ms1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/multiscrew1.h5'),\n",
    "        'ms2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/multiscrew2.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter3.h5')}\n",
    "    ]\n",
    "\n",
    "def connectToServer():\n",
    "    conn = None\n",
    "    try:\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(host=\"ls-491dfa0f47b6c73fb81aa4b4794c82f223f8cc98.cxfmrdeq6htd.ap-northeast-2.rds.amazonaws.com\",\n",
    "                                database=\"flask_capstone\",\n",
    "                                user=\"dbmasteruser\",\n",
    "                                password=\"g<#wHS>79|E!pGF9JJ7!$a[?&nLA?aP%\",\n",
    "                                port=5432)\n",
    "\n",
    "        print('PostgreSQL database version:')\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('SELECT version()')\n",
    "        db_version = cur.fetchone()\n",
    "        cur.close()\n",
    "        print(db_version)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Exception\")\n",
    "        print(error)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b80e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadImageFromServerAndGetLocalPath(id):\n",
    "    ## DBÏóêÏÑú idÏóê Ìï¥ÎãπÌïòÎäî ÌäúÌîåÏùÑ select\n",
    "    cur = CONN.cursor()\n",
    "    cur.execute(\"select image, type from public.image where id=%s\", (id, ))\n",
    "    tup = cur.fetchone()\n",
    "    cur.close()\n",
    "\n",
    "    ## select Îêú ÌäúÌîå Ïù¥ÎØ∏ÏßÄ(binary)Î•º numpy.ndarrayÎ°ú Î≥ÄÌôò + type Ï†ÄÏû•\n",
    "    binImage = tup[0].tobytes()\n",
    "    npImage = cv2.imdecode(np.frombuffer(binImage, np.uint8), -1)\n",
    "    datasetType = tup[1]\n",
    "\n",
    "    ## fetchÌïú Ïù¥ÎØ∏ÏßÄÎ•º localÏóê ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "    path = f'{round(time.time() * 1000)}.jpg'\n",
    "    cv2.imwrite(path, npImage)\n",
    "\n",
    "    ## Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú, Îç∞Ïù¥ÌÑ∞ÏÖã type Î¶¨ÌÑ¥\n",
    "    return path, datasetType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4b9ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mh/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/mh/yolov5/\n",
    "import detect\n",
    "#%cd ..\n",
    "\n",
    "def processImage(path, datasetType):\n",
    "    ## Ïù¥ÎØ∏ÏßÄ ÏùΩÍ∏∞\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    ## Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄ\n",
    "    result = image.copy()\n",
    "\n",
    "    ## yoloÎ°ú Î∂ÄÌíà ÌÉêÏßÄ\n",
    "    yoloResults = detect.run(weights=YOLOv5_MODELS_PATH[datasetType], source=path)\n",
    "\n",
    "    ## yolo Î∂ÄÌíà ÌÉêÏßÄ Í≤∞Í≥º ÏàúÌöå\n",
    "    for yoloResult in yoloResults:\n",
    "        ## Í≤∞Í≥º Ï∂îÏ∂ú (Î∂ÄÌíà Ïù¥Î¶Ñ, conf., Ï¢åÌëúÍ∞í)\n",
    "        spl = yoloResult[0].split(' ')\n",
    "        part, conf = spl[0], spl[1]\n",
    "        x1, y1 = int(yoloResult[1][0]), int(yoloResult[1][1])\n",
    "        x2, y2 = int(yoloResult[1][2]), int(yoloResult[1][3])\n",
    "\n",
    "        ## Î∂ÄÌíà crop\n",
    "        croppedImage = image[y1:y2, x1:x2]\n",
    "        croppedImage = cv2.resize(croppedImage, (224, 224))\n",
    "        croppedImage = np.expand_dims(croppedImage, axis=0)\n",
    "        \n",
    "        ## CNNÏúºÎ°ú Î∂ÄÌíà class Î∂ÑÎ•ò\n",
    "        predRN50 = RN50_MODELS[datasetType][part].predict(croppedImage)\n",
    "\n",
    "        ## Í≤∞Í≥ºÎ•º ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÏóê Í∑∏Î¶¨Í∏∞\n",
    "        if np.argmax(predRN50[0]) == 0:  # Ï†ïÏÉÅ\n",
    "            result = cv2.rectangle(result, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "            cv2.putText(result, part + ': Normal', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 5)\n",
    "        else:  # Î∂àÎüâ\n",
    "            result = cv2.rectangle(result, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
    "            cv2.putText(result, part + ': Defect', (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 5)\n",
    "    \n",
    "    ## Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ ÏÇ≠Ï†ú\n",
    "    os.remove(path)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd05af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadResultToServer(result, id):\n",
    "    #### Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄÎ•º binaryÎ°ú Î≥ÄÌôò\n",
    "    _, encoded = cv2.imencode('.jpeg', result)\n",
    "    binImage = encoded.tobytes()\n",
    "\n",
    "    ### DB ÌäúÌîåÏùò result Ïª¨Îüº update\n",
    "    cur = CONN.cursor()\n",
    "    cur.execute('''update public.image set result=%s where id=%s''', (binImage + b'1', id, ))\n",
    "    CONN.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a79cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "PostgreSQL database version:\n",
      "('PostgreSQL 14.7 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 7.3.1 20180712 (Red Hat 7.3.1-12), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "RN50_MODELS = loadRN50()\n",
    "CONN = connectToServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5002\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7034398 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494876490.jpg: 384x640 1 c1, 1 c2, 1 ms1, 1 ms2, 1 s1, 1 s2, 1 sp3, 54.3ms\n",
      "Speed: 1.1ms pre-process, 54.3ms inference, 6.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3beb39480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3beb39c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:01:20] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494885361.jpg: 384x640 1 c, 1 ms, 1 sp2, 43.2ms\n",
      "Speed: 0.4ms pre-process, 43.2ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp18\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:01:26] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494891564.jpg: 384x640 1 c, 1 ms, 1 s1, 1 s2, 1 sp2, 1 sp3, 43.8ms\n",
      "Speed: 0.4ms pre-process, 43.8ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp19\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:01:33] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494976314.jpg: 480x640 1 c, 1 ms, 2 s1s, 1 s2, 1 sp2, 56.0ms\n",
      "Speed: 0.4ms pre-process, 56.0ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:02:56] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494980474.jpg: 384x640 1 c, 1 ms, 2 s1s, 1 s2, 1 sp2, 1 sp3, 45.3ms\n",
      "Speed: 0.4ms pre-process, 45.3ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp21\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:03:01] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685494985485.jpg: 384x640 1 c, 1 ms, 1 s1, 1 s2, 1 sp2, 1 sp3, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:03:06] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7034398 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685495004016.jpg: 384x640 1 c1, 1 c2, 1 ms1, 1 ms2, 1 s1, 1 s2, 1 sp3, 45.1ms\n",
      "Speed: 0.6ms pre-process, 45.1ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp23\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:03:25] \"POST /process HTTP/1.1\" 200 -\n",
      "YOLOv5 üöÄ v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685495012268.jpg: 384x640 1 c, 1 ms, 1 s1, 1 s2, 1 sp2, 1 sp3, 45.7ms\n",
      "Speed: 0.4ms pre-process, 45.7ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2023 10:03:33] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "YOLOv5_MODELS_PATH = [\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_s.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_m.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_as.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_am.pt'\n",
    "]\n",
    "\n",
    "@app.route('/')\n",
    "def hello(): # Web Í∏∞Î≥∏ Ï†ëÏÜç ÌôîÎ©¥ (Ï£ºÏÜå ÏûÖÎ†•ÌïòÍ≥† Îì§Ïñ¥Í∞ÄÎ©¥ ÎÇòÏò§Îäî default ÌôîÎ©¥)\n",
    "  return \"<h1>Welcome to Flask</h1>\"\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def handle_request():\n",
    "  fail = False\n",
    "  value = request.json.get('value') # image id (DB)\n",
    "\n",
    "  path, datasetType = downloadImageFromServerAndGetLocalPath(value)\n",
    "  result = processImage(path, datasetType)\n",
    "  uploadResultToServer(result, value)\n",
    "  \n",
    "  if fail:\n",
    "    return jsonify({'result': -1})\n",
    "      \n",
    "  return jsonify({'result': value}) # ÏôÑÎ£å ÌõÑ image id Î∞òÌôò\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  app.run(port='5002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427c45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
